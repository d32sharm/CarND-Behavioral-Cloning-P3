{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the network structure and train the network\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Normalize\n",
    "model.add(Lambda(lambda x: x/127.5 - 1.0,input_shape=(66,200,3)))\n",
    "\n",
    "# Add three 5x5 convolution layers (output depth 24, 36, and 48), each with 2x2 stride\n",
    "model.add(Conv2D(24, (5, 5), strides=(2, 2), padding='valid', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(ELU())\n",
    "model.add(Conv2D(36, (5, 5), strides=(2, 2), padding='valid', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(ELU())\n",
    "model.add(Conv2D(48, (5, 5), strides=(2, 2), padding='valid', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(ELU())\n",
    "\n",
    "#model.add(Dropout(0.50))\n",
    "\n",
    "# Add two 3x3 convolution layers (output depth 64, and 64)\n",
    "model.add(Conv2D(64, (3, 3), padding='valid', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(ELU())\n",
    "model.add(Conv2D(64, (3, 3), padding='valid', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(ELU())\n",
    "\n",
    "# Add a flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add three fully connected layers (depth 100, 50, 10), tanh activation (and dropouts)\n",
    "model.add(Dense(100, kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(ELU())\n",
    "#model.add(Dropout(0.50))\n",
    "model.add(Dense(50, kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(ELU())\n",
    "#model.add(Dropout(0.50))\n",
    "model.add(Dense(10, kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(ELU())\n",
    "#model.add(Dropout(0.50))\n",
    "\n",
    "# Add a fully connected output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile and train the model, \n",
    "#model.compile('adam', 'mean_squared_error')\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_roi(image):\n",
    "    img = image[55:121, 50:250, :]\n",
    "    return img\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # crop the ROI\n",
    "    img = crop_roi(image)\n",
    "    \n",
    "    # Apply colorspace conversion from BGR to YUV\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "       \n",
    "    return img\n",
    "\n",
    "def read_data(csv_path):\n",
    "    train_df = pd.read_csv(csv_path, names=['center', 'left', 'right', 'steering', 'throttle', 'brake', 'speed'])\n",
    "    train_df['steering_left'] = train_df['steering'] + 0.25\n",
    "    train_df['steering_right'] = train_df['steering'] - 0.25\n",
    "    \n",
    "    img_data = np.array(train_df['center'])\n",
    "    img_data = np.append(img_data, train_df['left'])\n",
    "    img_data = np.append(img_data, train_df['right'])\n",
    "    \n",
    "    angle_labels = np.array(train_df['steering'])\n",
    "    angle_labels = np.append(angle_labels, train_df['steering_left'])\n",
    "    angle_labels = np.append(angle_labels, train_df['steering_right'])\n",
    "    \n",
    "    return img_data, angle_labels, train_df\n",
    "#     for index, row in train_df.iterrows():\n",
    "#         img_left.append(preprocess_image(cv2.imread(row['left'])))\n",
    "#         img_center.append(preprocess_image(cv2.imread(row['center'])))\n",
    "#         img_right.append(preprocess_image(cv2.imread(row['right'])))\n",
    "    \n",
    "#     return train_df\n",
    "\n",
    "def generate_training_data(batch_size, data, labels):\n",
    "    num_samples = data.size\n",
    "    \n",
    "    while True:\n",
    "        indxs = np.random.choice(num_samples, batch_size, replace=True)\n",
    "\n",
    "        batch_data, batch_labels = data[indxs], labels[indxs]\n",
    "        batch_imgs = []\n",
    "\n",
    "        for img_path in batch_data:\n",
    "            batch_imgs.append(preprocess_image(cv2.imread(img_path)))\n",
    "        \n",
    "        yield (np.array(batch_imgs), batch_labels)\n",
    "    \n",
    "    \n",
    "def get_image_data(data):\n",
    "    img_data = []\n",
    "    \n",
    "    for img_path in data:\n",
    "        img_data.append(preprocess_image(cv2.imread(img_path)))\n",
    "    \n",
    "    return np.array(img_data)\n",
    "    \n",
    "\n",
    "data, labels, train_df = read_data('/Users/dhruvsharma/Desktop/4B/driving_log.csv')\n",
    "data, labels = shuffle(data, labels)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size = 0.2, random_state=42)\n",
    "\n",
    "train_gen = generate_training_data(64, train_data, train_labels)\n",
    "test_img_data = get_image_data(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('model_{epoch:02d}.h5', period=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_gen, epochs=25, validation_data=(test_img_data,test_labels), verbose=1, steps_per_epoch=340, callbacks=[checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
